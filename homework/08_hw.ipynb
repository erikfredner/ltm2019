{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Parts-of-speech tagging\n",
    "\n",
    "On 11-11, we learned about parts-of-speech (POS) tagging. This is a powerful way to disambiguate identically spelled words (homographs), as well as to search for specific types of content in our texts.\n",
    "\n",
    "## a. Using `nltk`, POS tag a text of your choosing. `print` the first 10 tuples containing the word and its tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Find all of the adverbs in your text, and count their frequencies. What are the 10 most frequent adverbs in your text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Generate a list of all of the sentences in your text containing a major character of your choice. `print` the first few sentences in your list.\n",
    "For the purposes of this question, we will only look at sentences containing that character's name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Using POS tagging to count, which verbs most frequently appear in the list of sentences you created for `1c`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e. Reflection: What errors did you notice in `nltk`'s parts-of-speech tagging, if any?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your response here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Named-entity recognition\n",
    "\n",
    "## a. Using the `ner_sents` function from the 11-11 notebook, perform a named entity recognition (NER) analysis on the text you used for question `1`. Print the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Based on `nltk`'s NER results, which places occur most frequently in your text?\n",
    "*Hint: Place names are associated with the label `GPE`, which stands for \"geo-political entity.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Using the `sent` column in your NER dataframe, `print` the sentences where one place of interest in your text occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Reflection: What meanings appear to be associated with the place name you chose based on these sentences? Are they what you would have expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your response here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generating content-related metadata (English)\n",
    "The essay we read by English (2016) generated new metadata *about the content* of novels in order to analyze change over time. We're going to do the same thing here.\n",
    "\n",
    "## a. For at least 10 books, create 1 new column of categorical metadata about the **content** of those books.\n",
    "\n",
    "Because we are going to use this metadata to run a Fisher's exact test, it is important that the data be **binary**, meaning it tests a condition that can be rendered as `True` or `False`. (To go back to the example from class, this is identical to the question of whether milk was poured first, or tea was poured first in the cup.)\n",
    "\n",
    "### Examples of categorical metadata\n",
    "Feel free to use any of these ideas. **But if you can, create data that is releavant to your project!**\n",
    "\n",
    "| Metadata category   | Category True                   | Category False                      |\n",
    "|---------------------|---------------------------------|-------------------------------------|\n",
    "| Time (like English) | Set more than 20 years ago      | Set 20 or fewer years ago           |\n",
    "| Setting             | Set in the USA                  | Not set in the USA                  |\n",
    "| Setting             | Set in a city                   | Not set in a city                   |\n",
    "| Style               | Written in the first-person     | Not in the first-person             |\n",
    "| Style               | Has 1 main protagonist          | Has more than 1 protagonist         |\n",
    "| Class               | Main characters are upper-class | Main characters are not upper-class |\n",
    "| Subject             | Protagonist is female           | Protagonist is not female           |\n",
    "| Subject             | Protagonist is unmarried        | Protagonist is married              |\n",
    "| History             | Book published before 1945      | Book published after 1945           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Add your new metadata to your existing metadata table. Show your metadata below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Practicing with Fisher's on our new metadata\n",
    "## a. Using the `fish` function from the 11-13 notebook, run a Fisher's exact test using the metadata you generated for question `3a` to create your groups.\n",
    "For example, just as we used `Democrats` and `Republicans` as our groups in class, your groups might be `Set in a city` and `Not set in a city` if you generated metadata about that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Reflection: In what ways did you expect your metadata groups to differ? How did they differ in practice, according to the results of the Fisher's exact test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your response here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. The digital cultural record (Risam)\n",
    "## a. By creating new metadata, are you contributing to the digital cultural record Risam discussed? If not, what more would you need to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your response here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
