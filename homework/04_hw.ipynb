{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 04\n",
    "Several of these problems ask you to write functions that require *similar* functionality. Don't feel like you have to reinvent the wheel! If a function from an earlier question will work in a later question, by all means reuse it.\n",
    "\n",
    "If you use texts from Gutenberg, you may want to remove the copyright information outside of your functions. Please `print` the first 100 characters or so of your text so I know that you cleaned it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Counting vowels with lists and `for` loops\n",
    "\n",
    "Write a function that performs the following tasks for a text of your choice:\n",
    "\n",
    "1. Cleans your text.\n",
    "2. Splits any text into a list of words by using `' '` as the separator.\n",
    "3. For every word in your list, count the number of vowels (`a`, `e`, `i`, `o`, and `u`) in that word.\n",
    "4. `print` the total number of each vowel used in the whole text.\n",
    "5. Run your function on a text of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Beating Mendenhall at his own game\n",
    "\n",
    "One of the earliest digital humanists may have been T.C. Mendenhall. In 1887, Mendenhall published a paper in *Science* in which he counted the character lengths of all of the words used by several contemporary authors. He wanted to test whether the distribution of the lengths of words that authors use are distinctive of their style. Like many digital humanists, he used this method to try to determine whether Shakespeare wrote all of the plays attributed to him.\n",
    "\n",
    "Write a function that does Mendenhall's research quickly. Given any text, the function should:\n",
    "\n",
    "1. Clean your text.\n",
    "2. Split it into a list of words.\n",
    "3. Calculate the length of every word in the list.\n",
    "4. Append the lengths of every word into a list of results.\n",
    "5. `print` the minimum, maximum, and mean word length from your results.\n",
    "\n",
    "(Even if this takes you a little bit to write, be thankful that you're not Mendenhall counting characters by hand!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Slice for Type-Token Ratio (TTR)\n",
    "Write one or more functions that perform the following tasks.\n",
    "\n",
    "Given a text of your choosing,\n",
    "\n",
    "1. Clean it. \n",
    "2. Make a list containing all of the words in your text. Be sure to exclude punctuation from this list.\n",
    "3. Create a new list containing 2% of all of the the tokens in your text in the order in which they appear.\n",
    "4. Calculate the type-token ratio (TTR) of that 2% chunk.\n",
    "5. Append that TTR score to a new list.\n",
    "6. Repeat this process for each 2% chunk in your text.\n",
    "\n",
    "To clarify the idea of 2% of your tokens: If your text were 10000 words long, its first 2% chunk would be comprised of the first 200 words in the text in the order that they appear. The next 2% chunk would consist of the 200 words immediately following the first 200, and so on until your text is exhausted.\n",
    "\n",
    "If your text cannot be divided into exactly even chunks, it's ok if your first or last chunk is of a different size than all of the others.\n",
    "\n",
    "Remember, to calculate TTR you will have to use the `set()` function to calculate the number of unique words (types) and divide by the total number of tokens. See the notebook for 10-16 for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Reading for TTR\n",
    "Now, we're going to use your TTR scores to read some passages.\n",
    "\n",
    "1. `print` the name of your text, along with the minimum TTR score, the maximum TTR score, and the mean TTR score from your list of results.\n",
    "2. Identify which slices of your text correspond with the minimum, maximum, and mean TTR scores.\n",
    "3. `print` those slices as strings, not as lists of words.\n",
    "4. Read each of your sections.\n",
    "5. Write a paragraph comparing and contrasting them. How different do they seem? What is happening in each one? What differences in form or content can you detect, if any, that might account for the TTR differences between the passages?\n",
    "\n",
    "Hint: In order to match slices with your min/max/mean scores, you will need a way to identify which text slices correspond with which TTR scores. It might help to think back to our use of indices with `find`.\n",
    "\n",
    "*Optional challenge*: Print your sections with their original punctuation. You'll have to figure out how to use your word lists to access the correct position inside of your source text. You may be able to modify the `kwic` function to solve this problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
