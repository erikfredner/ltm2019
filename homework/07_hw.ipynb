{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Counting words in sentences\n",
    "\n",
    "Now, we have the ability to split texts into **semantically meaningful** units like the sentence. This can help us step away from some of the problems we have seen with the \"bag of words\" approach, where we count all of the words in each text as part of the same group. Instead, we can look at units that the *author* considered meaningful: Sentences, paragraphs, etc.\n",
    "\n",
    "Write a function that performs the following tasks. Given a path to a text, your function...\n",
    "\n",
    "1. Opens and reads the text file given by the path (i.e. `'~/Downloads/my_text.txt'`).\n",
    "2. Cleans the text of formatting problems and erroneous characters.\n",
    "3. Splits the text into a list of sentences.\n",
    "4. Counts the number of tokens of every word type in every sentence.\n",
    "5. Appends a dictionary containing the word-counts, the sentence number, and the source text to an output list.\n",
    "6. Uses that output list to make a Pandas dataframe, where each row represents the word count of one *sentence*.\n",
    "7. Returns that dataframe.\n",
    "\n",
    "We have done each of these steps in previous assignments. So by all means, **reuse code!**\n",
    "\n",
    "Your dataframe should look something like this in the end. The `...` represents all of the words between `a` and `zebra`.\n",
    "\n",
    "| Text    | Sentence # | a   | aardvark | ... | zebra |\n",
    "|---------|------------|-----|----------|-----|-------|\n",
    "| hp1.txt | Sentence 1 | 2   | 0        | -   | 1     |\n",
    "| hp1.txt | Sentence 2 | 3   | 0        | -   | 0     |\n",
    "| hp1.txt | Sentence 3 | 1   | 1        | -   | 0     |\n",
    "| ...     | ...        | ... | ...      | ... | ...   |\n",
    "\n",
    "Your result will be structurally similar to a document-term matrix, but each row corresponds to a single sentence from a text rather than an entire document.\n",
    "\n",
    "**Run your function on one text of your choosing, and display the result.**\n",
    "\n",
    "*Hint: On 11-04, we discussed using `nltk` to split by sentences. You may use `nltk` to divide sentences, or you may write a custom function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here!\n",
    "def count_sents(text_path):\n",
    "    pass # `pass` tells Python to do nothing. it's conventionally used as a place-holder for functions you haven't written yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Counting by paragraphs\n",
    "You can modify the code you wrote for problem 1 to produce a similar function that automatically tallies all of the words in every *paragraph* instead of all of the words in every sentence.\n",
    "\n",
    "For the purposes of this assignment, we will consider one paragraph to be **text that exists between two `\\n` (newline) characters.**\n",
    "\n",
    "There are several ways you could approach this problem of splitting by paragraph. The code you wrote for problem 1 will provide 80% of the functionality you need.\n",
    "\n",
    "However you get there, your result should look like this:\n",
    "\n",
    "| Text    | Paragraph # | a   | aardvark | ... | zebra |\n",
    "|---------|-------------|-----|----------|-----|-------|\n",
    "| hp1.txt | Paragraph 1 | 6   | 1        | -   | 0     |\n",
    "| hp1.txt | Paragraph 2 | 29  | 0        | -   | 2     |\n",
    "| hp1.txt | Paragraph 3 | 108 | 0        | -   | 2     |\n",
    "| ...     | ...         | ... | ...      | ... | ...   |\n",
    "\n",
    "\n",
    "**Run your function on one text of your choosing, and display the result.**\n",
    "\n",
    "Extra challenge: Of course, paragraphs are really more complex than the text between `\\n` characters. How could you modify your function to catch those errors? Which of the \"paragraphs\" in your results seemed incorrect, and what would you need to do to fix those particular errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here!\n",
    "def count_grafs(text_path):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Why counting by sentences and paragraphs?\n",
    "Write a few sentences below about the value of these functions you have just written.\n",
    "\n",
    "1. What are the strengths of counting by sentence or paragraph as opposed to the \"bag of words\" approach?\n",
    "2. What are the weaknesses of counting by sentence or paragraph?\n",
    "3. What is one question that you could use the results of your sentence- or paragraph-splitting functions to answer?\n",
    "4. Are there other scales of text we should consider? What about the chapter? The beginning, middle, and end? How could we access them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your response here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Choose two comparison groups within your metadata\n",
    "Our readings this week emphasized the problems and opportunities associated with various techniques for \"normalizing\" data.\n",
    "\n",
    "With those readings in mind, which groups within your metadata table could you use to practice the techniques we discussed on 11-06 to compare the State of the Union addresses of Republican and Democratic presidents?\n",
    "\n",
    "In thinking about the groups you choose, I would like you to reflect on a few things:\n",
    "1. In what ways are the categories for your chosen groups imperfect or insufficient?\n",
    "2. Could the metadata be improved?\n",
    "3. If so, is there a way that you could imagine making that improvement?\n",
    "\n",
    "**If there are groups that you intend to analyze or compare for your final project, choose them for this assignment!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Your response here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Comparing text groups\n",
    "The purpose of this problem is to practice the methods of group comparison that we discussed in class on 11-06.\n",
    "\n",
    "Using the groups that you chose in question 4, perform each of the following analyses we discussed in class:\n",
    "\n",
    "1. Difference of means (scaled frequencies)\n",
    "2. Term frequency `*` inverse document frequency (scaled frequencies)\n",
    "3. Fisher's exact test (raw counts)\n",
    "\n",
    "**Remember to use a DTM with scaled frequencies for 1 and 2, and raw frequencies for 3.**\n",
    "\n",
    "You may reuse all of the code included in the 11-06 notebook, including `make_dtm`. In the notebooks, you will find functions for tf`*`idf and Fisher's exact test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Analyzing your results\n",
    "\n",
    "Compare and contrast the results you saw for each of the methods of comparing groups of texts. How were they similar? How were they different? Which one(s), if any, do you see as helpful for the analyses you want to perform for your final project?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
