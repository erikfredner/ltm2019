{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Slice and dice and Type-Token Ratio (TTR)\n",
    "Write a function that performs the following tasks. Given a text of your choosing,\n",
    "\n",
    "1. Clean it. (If you use texts from Gutenberg, you may remove the copyright information outside of the function. Please `print` the first 100 characters or so of your text so I know that you cleaned it.)\n",
    "2. Make a list containing all of the words in your text.\n",
    "3. Create a new list containing 2% of all of the the tokens in your text in the sequence they appear. There are many different ways you could accomplish this goal; I leave it up to you to decide how to approach it.\n",
    "4. Calculate the type-token ratio **for every** 2% chunk in your text. (If your text cannot be divided into exactly even chunks, it's ok if some are different.)\n",
    "5. Save your TTR scores in a new list.\n",
    "6. Print the name of the text, the minimum TTR score, the maximum TTR score, and the mean TTR score.\n",
    "\n",
    "Remember, to calculate TTR you will have to use the `set()` function to calculate the number of unique words (types) and divide by the total number of tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reading for TTR\n",
    "Now, using your list of TTR scores, we're going to use your TTR scores to read some passages.\n",
    "\n",
    "1. Using your min, max, and mean TTR scores, `print` the sections of your text that correspond with those results. Make sure to print these sections *with* punctuation!\n",
    "2. Read each of your sections in turn, thinking about the differences between their TTR scores.\n",
    "3. Write a paragraph comparing and contrasting them. How different do they seem? What is happening in each one? What differences in form or content can you detect, if any, that might account for the differences between the passages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extracting vowels with lists and loops\n",
    "\n",
    "Write a function that performs the following tasks:\n",
    "\n",
    "1. Splits any text into a list of words by using `' '` as the separator.\n",
    "2. For every word, count the number of vowels (`a`, `e`, `i,` `o`, and `u`) in that word.\n",
    "3. `print` the total number of each vowel used in the whole text.\n",
    "4. Test your function on a text of your choice, and `print` your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Beating Mendenhall at his own game\n",
    "\n",
    "One of the earliest digital humanists may have been T.C. Mendenhall. In 1887, Mendenhall published a paper in *Science* in which he counted the character lengths of all of the words used by contemporary authors. He wanted to test whether the distribution of the lengths of words that authors use are distinctive of their style. He used this method to try to determine whether Shakespeare wrote all of the plays attributed to him.\n",
    "\n",
    "Write a function that does Mendenhall's research quickly. Given any text,\n",
    "\n",
    "1. Split it into a list of words.\n",
    "2. Calculate the length of every word in the list.\n",
    "3. Output the lengths of every word into a new list called `result`.\n",
    "\n",
    "(Even if this takes you a little bit to write, be thankful that you're not Mendenhall counting characters by hand!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
