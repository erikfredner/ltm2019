{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review from homework\n",
    "Everyone figured out ways to improve the `kwic` functions, which is great. One thing that might have made your lives easier is the idea that you can place a `return` statement wherever you want in the function. It doesn't necessarily have to be at the end. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_even(num):\n",
    "    if num % 2 == 0:\n",
    "        return 'even' # note the early return\n",
    "    else:\n",
    "        print(num,'is not even. Try again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with `split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', '', 'string', '', '', 'has', '', '', '', '', '', 'many', '', '', 'extra', '', '', '', 'spaces']\n"
     ]
    }
   ],
   "source": [
    "s = 'this  string   has      many   extra    spaces'\n",
    "l = s.split(' ')\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'string', 'has', 'many', 'extra', 'spaces']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while '' in l:\n",
    "    del l[l.index('')]\n",
    "\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of ways of approaching this problem. We will discuss another, the `for` loop soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the `join` method\n",
    "Sometimes we want to convert lists of words into strings. We can do that with `join`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['To', 'each', 'their', 'own']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To each their own'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example the `' '` is the `sep` inserted between the elements of the list. Just as when we `split(' ')` and we get each word as an element in the list, so too do we `join` elements in the list with an object between them.\n",
    "\n",
    "We can read the above as:\n",
    "\n",
    "\"`join` each element of the list `l` with the `sep` `' '`.\"\n",
    "\n",
    "As with `split`, you can use any character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toeachtheirown'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To\n",
      "each\n",
      "their\n",
      "own\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `for` loops\n",
    "`for` loops are the other main looping construct in Python. They're similar to `while` loops.\n",
    "\n",
    "`while` loops execute until their condition changes from `True` to `False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm meltingggggggggggg\n",
      "I'm meltinggggggggggg\n",
      "I'm meltingggggggggg\n",
      "I'm meltinggggggggg\n",
      "I'm meltingggggggg\n",
      "I'm meltinggggggg\n",
      "I'm meltingggggg\n",
      "I'm meltinggggg\n",
      "I'm meltingggg\n",
      "I'm meltinggg\n",
      "I'm meltingg\n",
      "I'm melting\n",
      "I'm meltin\n",
      "I'm melti\n",
      "I'm melt\n",
      "I'm mel\n",
      "I'm me\n",
      "I'm m\n",
      "I'm \n",
      "I'm\n",
      "I'\n",
      "I\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = 'I\\'m meltinggggggggggggg'\n",
    "\n",
    "while len(s) > 0:\n",
    "    s = s[:-1] # slice off the last character of the string\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By contrast, `for` loops execute on *every element in a sequence* until the sequence is exhausted. Here's an easy example. Remember that Python's lists are ordered sequences of elements, and thus one of the main objects we will be using with loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "seuss = ['thing 0', 'thing 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thing 0\n",
      "thing 1\n"
     ]
    }
   ],
   "source": [
    "for x in seuss:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A functionally equivalent `while` loop would destroy our list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thing 0\n",
      "thing 1\n"
     ]
    }
   ],
   "source": [
    "while seuss: # this checks if seuss exists\n",
    "    print(seuss[0])\n",
    "    del seuss[0] # then we have to explicitly delete the element in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.0125\n",
      "0.015\n",
      "[4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "l = [4,5,6]\n",
    "\n",
    "for x in l:\n",
    "    print(x / 400)\n",
    "\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General form of the `for` loop\n",
    "\n",
    "```python\n",
    "for each_element in my_sequence:\n",
    "    # do something\n",
    "```\n",
    "\n",
    "Like `while` loops, `for` loops execute all of their indented code, then return to the top to check their condition. If there is another element in the series, the `for` loop begins again. Once all of the elements in the sequence have been operated on, the `for` loop ends.\n",
    "\n",
    "\n",
    "Let's look at an example relevant for this class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['After', 'great', 'pain,', 'a', 'formal', 'feeling', 'comes', '–']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dickinson = 'After great pain, a formal feeling comes –'\n",
    "dickinson_list = dickinson.split(' ')\n",
    "dickinson_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(variable):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After\n",
      "great\n",
      "pain,\n",
      "a\n",
      "formal\n",
      "feeling\n",
      "comes\n",
      "–\n"
     ]
    }
   ],
   "source": [
    "for x in dickinson_list:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of those lines repesents one full execution of the code inside of the loop (`print(word)`) as you can see here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 After\n",
      "1 great\n",
      "2 pain,\n",
      "3 a\n",
      "4 formal\n",
      "5 feeling\n",
      "6 comes\n",
      "7 –\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for word in dickinson_list:\n",
    "    print(counter, word)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comes'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dickinson_list[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One tricky thing about `for` loops is that the name you give to the iterator (`word` above) is arbitrary. Above, I chose a name that makes semantic sense, but there's no reason that you can't use the same iterator name for every `for` loop if it helps you remember the structure.\n",
    "\n",
    "It's common to use `x` in `for` loops and other short functions. As you can see, it does not change the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After\n",
      "great\n",
      "pain,\n",
      "a\n",
      "formal\n",
      "feeling\n",
      "comes\n",
      "–\n"
     ]
    }
   ],
   "source": [
    "for x in dickinson_list:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `for` loops use the same indentation logic as `while` loops and functions. You indent under the `for` loop to choose code to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After great pain, a formal feeling comes –'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dickinson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`for` loops can be run on any object with a length. So strings work, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dickinson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 A\n",
      "1 f\n",
      "2 t\n",
      "3 e\n",
      "4 r\n",
      "5  \n",
      "6 g\n",
      "7 r\n",
      "8 e\n",
      "9 a\n",
      "10 t\n",
      "11  \n",
      "12 p\n",
      "13 a\n",
      "14 i\n",
      "15 n\n",
      "16 ,\n",
      "17  \n",
      "18 a\n",
      "19  \n",
      "20 f\n",
      "21 o\n",
      "22 r\n",
      "23 m\n",
      "24 a\n",
      "25 l\n",
      "26  \n",
      "27 f\n",
      "28 e\n",
      "29 e\n",
      "30 l\n",
      "31 i\n",
      "32 n\n",
      "33 g\n",
      "34  \n",
      "35 c\n",
      "36 o\n",
      "37 m\n",
      "38 e\n",
      "39 s\n",
      "40  \n",
      "41 –\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for x in dickinson:\n",
    "    print(counter,x)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`enumerate` is a special function that generates an index value (given by the variable `i` above) for each element in a sequence. It's a quick method in Python for doing the equivalent of what I did above with the variable `counter +=1 ` for every iteration of the `for` loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows that `for` loops work on *each element* in the given series. Since strings measure by character, the `for` loop executes one character at a time.\n",
    "\n",
    "That's why they're so useful for us when we're working with lists: we can perform actions one *word* at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['After', 'great', 'pain,', 'a', 'formal', 'feeling', 'comes', '–']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dickinson_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(dickinson_list):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER\n",
      "GREAT\n",
      "PAIN,\n",
      "aaaaaaaaaaaaaaaaaaaa\n",
      "lamrof\n",
      "gnileef\n",
      "semoc\n",
      "–\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(dickinson_list):\n",
    "    if i < 3:\n",
    "        print(word.upper())\n",
    "    if i == 3:\n",
    "        print(word * 20)\n",
    "    if i > 3:\n",
    "        print(word[::-1]) # this is a little slicing trick to reverse a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `for` loops in `for` loops\n",
    "We may want to perform operations in series on objects within our lists. That's not a problem! We can put `for` loops inside other `for` loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['After', 'great', 'pain,', 'a', 'formal', 'feeling', 'comes', '–']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dickinson_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word is After\n",
      "a\n",
      "f\n",
      "t\n",
      "E\n",
      "r\n",
      "word is great\n",
      "g\n",
      "r\n",
      "E\n",
      "A\n",
      "t\n",
      "word is pain,\n",
      "p\n",
      "A\n",
      "I\n",
      "n\n",
      ",\n",
      "word is a\n",
      "A\n",
      "word is formal\n",
      "f\n",
      "O\n",
      "r\n",
      "m\n",
      "A\n",
      "l\n",
      "word is feeling\n",
      "f\n",
      "E\n",
      "E\n",
      "l\n",
      "I\n",
      "n\n",
      "g\n",
      "word is comes\n",
      "c\n",
      "O\n",
      "m\n",
      "E\n",
      "s\n",
      "word is –\n",
      "–\n"
     ]
    }
   ],
   "source": [
    "for word in dickinson_list:\n",
    "    print('word is', word)\n",
    "    for character in word:\n",
    "        if character in ['a','e','i','o','u']:\n",
    "            print(character.upper())\n",
    "        else:\n",
    "            print(character.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, our outside `for` loop looks at one series: the list `dickinson_list`. The inside `for` loop considers each element of `dickinson_list` as a series. Since each element is a string of characters, it treats each of those characters in sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appending results to a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time we will not want to `print` our results to the terminal like this. Instead, we will want to `append` our results to another list to perform further calculations on.\n",
    "\n",
    "To do this in Python, we need to initialize an empty list, and `append` values to it as our operations are performed. Here's a reminder about how `append` works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it', 'was', 'all', 'a', 'dream']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biggie = ['it','was','all','a']\n",
    "biggie.append('dream')\n",
    "biggie # this works because lists are mutable. you do *not* have to reassign biggie to append"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must have an existing list in order to use `append`. It's standard practice in Python to initialize an empty list and add results to it as we process data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = []\n",
    "type(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_str = ''\n",
    "type(my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 0, 3, 3, 3, 3, 0, 'add thisadd thisadd this']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = [1, 0, 0, 1, 1, 1, 1, 0, 'add this']\n",
    "output_list = [] # initialize empty list outside of the for loop\n",
    "\n",
    "for x in input_data:\n",
    "    output_list.append(x * 3)\n",
    "    \n",
    "output_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [234, 1, .97, 200, 3, 3, 3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.97, 1, 3, 3, 3, 3, 200, 234]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it sorts low to high by default. If you want high to low:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[234, 200, 3, 3, 3, 3, 1, 0.97]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(l, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sorted` also can apply to lists of characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After great pain, a formal feeling comes –'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dickinson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dickinson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = []\n",
    "for x in dickinson:\n",
    "    chars.append(x)\n",
    "    print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'f', 't', 'e', 'r', ' ', 'g', 'r', 'e', 'a', 't', ' ', 'p', 'a', 'i']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ',', 'A', 'a', 'a', 'a', 'a', 'c', 'e']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(chars)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't get tripped up by this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'f', 't', 'e', 'r', ' ', 'g', 'r', 'e', 'a', 't', ' ', 'p', 'a', 'i']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', ' ', 'A', 'a', 'a', 'e', 'e', 'f', 'g', 'i', 'p', 'r', 'r', 't', 't']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(chars[:15]) # only sorts the first 15 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic stats on lists\n",
    "Collecting basic stats about lists of numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[234, 1, 0.97, 200, 3, 3, 3, 3]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "447.97"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.99625"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arithmetic mean or average: sum of the values divided by the number of values\n",
    "sum(l) / len(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will cover much more advanced ways to collect statistics soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning with `for` loops\n",
    "Perhaps you can see that `for` loops offer us an easy way to check words in our texts for stray punctuation.\n",
    "\n",
    "We're going to benefit from a Python function called `isalpha`, which returns a Boolean value depending on whether the characters passed to it are all part of the alphabet (i.e. A-Z capitalized or lowercase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'test'.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'t3st'.isalpha()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this same principle, we can `split` any string into a series of possible words, validate whether they really consist entirely of letters, and remove any characters that are *not* alphabetical so we don't lose possible words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 'This is my testing string. It has a lot of real words, but also some h0t g4rbage.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'my',\n",
       " 'testing',\n",
       " 'string.',\n",
       " 'It',\n",
       " 'has',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'real',\n",
       " 'words,',\n",
       " 'but',\n",
       " 'also',\n",
       " 'some',\n",
       " 'h0t',\n",
       " 'g4rbage.']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s']\n",
      "['s', 't']\n",
      "['s', 't', 'r']\n",
      "['s', 't', 'r', 'i']\n",
      "['s', 't', 'r', 'i', 'n']\n",
      "['s', 't', 'r', 'i', 'n', 'g']\n",
      "['w']\n",
      "['w', 'o']\n",
      "['w', 'o', 'r']\n",
      "['w', 'o', 'r', 'd']\n",
      "['w', 'o', 'r', 'd', 's']\n",
      "['h']\n",
      "['h', 't']\n",
      "['g']\n",
      "['g', 'r']\n",
      "['g', 'r', 'b']\n",
      "['g', 'r', 'b', 'a']\n",
      "['g', 'r', 'b', 'a', 'g']\n",
      "['g', 'r', 'b', 'a', 'g', 'e']\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for word in sample.split(' '):\n",
    "    if word.isalpha():\n",
    "        result.append(word)\n",
    "    else:\n",
    "        cleanword = []\n",
    "        for char in word:\n",
    "            if char.isalpha():\n",
    "                cleanword.append(char)\n",
    "                print(cleanword)\n",
    "                \n",
    "        result.append(''.join(cleanword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'string'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(['s', 't', 'r', 'i', 'n', 'g'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'my',\n",
       " 'testing',\n",
       " 'string',\n",
       " 'It',\n",
       " 'has',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'real',\n",
       " 'words',\n",
       " 'but',\n",
       " 'also',\n",
       " 'some',\n",
       " 'ht',\n",
       " 'grbage']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loop demonstrates two key ideas:\n",
    "1. We can loop in loops. Here, the external `for` loop checks each word, while the internal loop checks each character to see if it `isalpha`.\n",
    "2. We can initialize empty lists outside of loops, as with `result`. But we can also **initialize them inside of loops**, as with `cleanword`. Initializing a list inside of a loop causes it to be cleared out *each time the loop executes*. In this case, that is exactly what we want. If `cleanword` were initialized outside of the function, look what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'my',\n",
       " 'testing',\n",
       " 'string',\n",
       " 'It',\n",
       " 'has',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'real',\n",
       " 'stringwords',\n",
       " 'but',\n",
       " 'also',\n",
       " 'some',\n",
       " 'stringwordsht',\n",
       " 'stringwordshtgrbage']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "cleanword = []\n",
    "\n",
    "for word in sample.split(' '):\n",
    "    if word.isalpha():\n",
    "        result.append(word)\n",
    "    else:\n",
    "        for char in word:\n",
    "            if char.isalpha():\n",
    "                cleanword.append(char)\n",
    "                \n",
    "        result.append(''.join(cleanword))\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types and Tokens\n",
    "Corpus linguists make a distinction between types and tokens. Types are spellings of valid words (sometimes called the \"vocabulary\" for a given dataset), whereas tokens are instances of types.\n",
    "\n",
    "In the sentence \"the cat sat on the mat,\" there are 6 tokens and 5 types. The type \"the\" appears as two tokens here, which we can think of as simply instances of the type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Types | *n* Tokens |\n",
    "|---|---|\n",
    "|the|2|\n",
    "|cat|1|\n",
    "|sat|1|\n",
    "|on|1|\n",
    "|mat|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this distinction between types and tokens gets complicated quickly. \"read\" and \"read\" have the same spelling, but mean different things in different contexts: the imperative (\"you read it!\"), past-tense (\"He read that book in 1995\"), present and habitual tenses (\"I read daily\"), etc. These are called \"homographs,\" words that are spelled the same but may be pronounced or mean differently.\n",
    "\n",
    "So far, we have only been counting `tokens` using `string.split(' ')`. But we don't need to reinvent the wheel: good tokenizers already exist that we can use if we learn how to `import`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `import` statements\n",
    "In Python, many functions and methods like `print` are loaded by default. But some are only used in special circumstances, so we have to ask Python to `import` them for a particular session. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-f84ab820532c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pi' is not defined"
     ]
    }
   ],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import * # this * imports all objects from math\n",
    "pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we `import` a Python library called `math` that contains the reserved word `pi`. Above I demonstrate two different methods of `import`. Usually you'll just want to use `import my_object`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "We can do the same thing with a library called `nltk`, which stands for Natural Language Tool Kit. It's a library written in Python designed to do some of the work we have been doing by hand to learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'can', 'help', 'us', 'out']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk # this may take a second to load!\n",
    "nltk.word_tokenize('This can help us out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nltk` isn't perfect. It gets tripped up by stuff like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sometimes', 'things-even', 'simple', 'things-cause', 'problems']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize('Sometimes things-even simple things-cause problems')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve its results by preprocessing our texts some. These will save us some time, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`re` is a special module that stands for regular expressions. It is the same system that Piper used to count punctuation. It may be most useful for us to count *arbitrary* amounts of whitespace, as in the string below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  ', ' ', ' ', ' \\t ', ' \\n  ', '   ']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.findall('\\s+', '  instances of multiple \\t spaces \\n  are.   present')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All you need to know is that the method `findall` from the library `re` can identify any amount of different sorts of whitespace in sequence. The special sequence `'\\s+'` finds the whitespace.\n",
    "\n",
    "We can use that flexibility to find *all* of the whitespace and replace it with spaces for simplicity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/e/Downloads/walden.txt') as thoreau:\n",
    "    thoreau = thoreau.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    for punct in string.punctuation:\n",
    "        text = text.replace(punct, ' ' + punct + ' ') # adding spaces to either side of any punctuation mark\n",
    "    \n",
    "    # this replaces *any* amount of spaces with a single space:\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    \n",
    "    # then we can use nltk's tokenizer\n",
    "    return nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "thoreau_toks = tokenize(thoreau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns as respectable version of the text with each punctuation mark as an element in the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rather',\n",
       " 'the',\n",
       " 'bulk',\n",
       " 'of',\n",
       " 'them',\n",
       " ',',\n",
       " 'I',\n",
       " 'lived',\n",
       " 'alone',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'woods',\n",
       " ',',\n",
       " 'a',\n",
       " 'mile',\n",
       " 'from',\n",
       " 'any',\n",
       " 'neighbor',\n",
       " ',',\n",
       " 'in',\n",
       " 'a',\n",
       " 'house',\n",
       " 'which',\n",
       " 'I',\n",
       " 'had',\n",
       " 'built',\n",
       " 'myself',\n",
       " ',',\n",
       " 'on',\n",
       " 'the',\n",
       " 'shore',\n",
       " 'of',\n",
       " 'Walden',\n",
       " 'Pond',\n",
       " ',',\n",
       " 'in',\n",
       " 'Concord',\n",
       " ',',\n",
       " 'Massachusetts',\n",
       " ',',\n",
       " 'and',\n",
       " 'earned',\n",
       " 'my',\n",
       " 'living',\n",
       " 'by',\n",
       " 'the',\n",
       " 'labor',\n",
       " 'of',\n",
       " 'my',\n",
       " 'hands',\n",
       " 'only',\n",
       " '.',\n",
       " 'I',\n",
       " 'lived',\n",
       " 'there',\n",
       " 'two',\n",
       " 'years',\n",
       " 'and',\n",
       " 'two',\n",
       " 'months',\n",
       " '.',\n",
       " 'At',\n",
       " 'present',\n",
       " 'I',\n",
       " 'am',\n",
       " 'a',\n",
       " 'sojourner',\n",
       " 'in',\n",
       " 'civilized',\n",
       " 'life',\n",
       " 'again',\n",
       " '.',\n",
       " 'I',\n",
       " 'should']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thoreau_toks[75:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify this script to include an option as to whether punctuation should be retained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, keep_punct = True):\n",
    "    if keep_punct is True:\n",
    "        for punct in string.punctuation:\n",
    "            text = text.replace(punct, ' ' + punct + ' ') # adding spaces to either side of any punctuation mark\n",
    "    else:\n",
    "        for punct in string.punctuation:\n",
    "            text = text.replace(punct, ' ') # adding spaces in the place of punctuation\n",
    "    \n",
    "    # this replaces *any* amount of spaces with a single space:\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    \n",
    "    # then we can use nltk's tokenizer\n",
    "    return nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "thoreau_toks = tokenize(thoreau, keep_punct = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['them',\n",
       " 'I',\n",
       " 'lived',\n",
       " 'alone',\n",
       " 'in',\n",
       " 'the',\n",
       " 'woods',\n",
       " 'a',\n",
       " 'mile',\n",
       " 'from',\n",
       " 'any',\n",
       " 'neighbor',\n",
       " 'in',\n",
       " 'a',\n",
       " 'house',\n",
       " 'which',\n",
       " 'I',\n",
       " 'had',\n",
       " 'built',\n",
       " 'myself',\n",
       " 'on',\n",
       " 'the',\n",
       " 'shore',\n",
       " 'of',\n",
       " 'Walden',\n",
       " 'Pond',\n",
       " 'in',\n",
       " 'Concord',\n",
       " 'Massachusetts',\n",
       " 'and',\n",
       " 'earned',\n",
       " 'my',\n",
       " 'living',\n",
       " 'by',\n",
       " 'the',\n",
       " 'labor',\n",
       " 'of',\n",
       " 'my',\n",
       " 'hands',\n",
       " 'only',\n",
       " 'I',\n",
       " 'lived',\n",
       " 'there',\n",
       " 'two',\n",
       " 'years',\n",
       " 'and',\n",
       " 'two',\n",
       " 'months',\n",
       " 'At',\n",
       " 'present',\n",
       " 'I',\n",
       " 'am',\n",
       " 'a',\n",
       " 'sojourner',\n",
       " 'in',\n",
       " 'civilized',\n",
       " 'life',\n",
       " 'again',\n",
       " 'I',\n",
       " 'should',\n",
       " 'not',\n",
       " 'obtrude',\n",
       " 'my',\n",
       " 'affairs',\n",
       " 'so',\n",
       " 'much',\n",
       " 'on',\n",
       " 'the',\n",
       " 'notice',\n",
       " 'of',\n",
       " 'my',\n",
       " 'readers',\n",
       " 'if',\n",
       " 'very',\n",
       " 'particular']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thoreau_toks[75:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type-Token ratio\n",
    "A common statistic in corpus linguistics/text mining is the type token ratio (TTR). It is defined simply by\n",
    "\n",
    "    TTR = (# of word types) / (# of word tokens)\n",
    "    \n",
    "Where\n",
    "\n",
    "* \\# of word **types** = the number of *unique* words in a list of words\n",
    "* \\# of word **tokens** = the number of *all* words, including repeated words; \n",
    "\n",
    "We can think of TTR as a measure of the *diversity* of a text's vocabulary. To return to our previous example, \"the cat sat on the mat\" has a high rate of linguistic diversity: 5 types over 6 tokens. Most of its words are unique.\n",
    "\n",
    "Arguably the short sentence with the lowest TTR in English is as follows:\n",
    "\n",
    "\"Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo.\"\n",
    "\n",
    "Linguists claim this is the [longest grammatically correct sentence in English using a single homograph](https://en.wikipedia.org/wiki/Buffalo_buffalo_Buffalo_buffalo_buffalo_buffalo_Buffalo_buffalo). The sense of the sentence is something like \"Buffalo bison, that other Buffalo bison bully, also bully Buffalo bison.\"\n",
    "\n",
    "Depending on whether you count Buffalo and buffalo as different types, we have a type token ratio of either 1/7 or 2/7.\n",
    "\n",
    "So, lower TTR means less diverse vocabulary and more repetition. Higher TTR measn more diverse vocabulary and lower rates of repetition.\n",
    "\n",
    "Of course, as soon as texts start getting longer than a sentence, the rate of TTR declines because language is necessarily repetitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating TTR\n",
    "\n",
    "We know how to get the number of words in a text at this point: We can call our `tokenizer` function on a text without retaining punctuation, and measure its `len`. \n",
    "\n",
    "But how do we get the number of `unique` words in a list? For that, we can use a new Python object called a `set`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'b', 'c'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = ['a','b','c','a']\n",
    "set(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`set` can be used for all kinds of things. For now, we're just going to use it to remove duplicates from lists. You'll also probably notice that `set` is enclosed in `{}`. We'll talk more about those soon, too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttr(text):\n",
    "    '''\n",
    "    Calculates the type-token ratio for any given text. Depends on function tokenize.\n",
    "    '''\n",
    "    tokens = tokenize(text, keep_punct=False)\n",
    "    types = set(tokens)\n",
    "    return len(types)/len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10052597364221973"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttr(thoreau) # long texts are very repetitive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttr(\"Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttr('the cat sat on the mat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
